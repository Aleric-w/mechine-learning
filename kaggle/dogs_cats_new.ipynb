{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载数据集，项目数据集来自Kaggle，[Dogs vs. Cats Redux](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data)\n",
    "\n",
    "使用kaggle-api下载：kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "if not os.path.isdir('train'):\n",
    "    if os.path.isfile('train.zip'):\n",
    "        os.system('unzip train.zip')\n",
    "    else:\n",
    "        print('FILES (train.zip) NOT FOUND, DOWNLOAD FIRST')\n",
    "\n",
    "if not os.path.isdir('test'):\n",
    "    if os.path.isfile('test.zip'):\n",
    "        os.system('unzip test.zip')\n",
    "    else:\n",
    "        print('FILES (test.zip) NOT FOUND, DOWNLOAD FIRST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dogs=[]\n",
    "cats=[]\n",
    "\n",
    "for file in os.listdir('train'):\n",
    "    if (file.split(sep='.')[0]=='cat'):\n",
    "        cats=np.append(cats,file)\n",
    "    else:\n",
    "        dogs=np.append(dogs,file)\n",
    "\n",
    "cat_lable=np.zeros(len(cats))\n",
    "dog_lable=np.zeros(len(dogs))+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异常值处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据观察训练数据集图片，发现存在以下两种情况：\n",
    "1.有一些图片内容并非猫狗，这种类型的图片是属于错误图片，直接作为异常值处理。\n",
    "2.此外此项目是为了识别是猫或者是狗，是一个二分类问题，因此在这个前提下不应该存在猫狗共存的图片，如果存在则会与项目目标二分类相违背，对于模型训练中的准确度也会产生较大影响，因此个人觉得如果同时存在猫狗，那么这类型图片也需要作为异常值处理。\n",
    "\n",
    "此处异常值模型使用imagenet多个模型top-50来做批量识别，当图片是第一种情况时，模型对于图片识别结果top-50中没有识别到给定标签的品种；当图片是第二种情况时，模型对于图片识别结果top-50中同时存在猫狗品种。使用多个模型去识别图片，对多个模型预测中存在以上两种异常值，分别求两种情况下的交集。考虑到模型识别的准确率问题，最后需要人为去识别图片是否需要做为异常处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "##  imagenet 分类中的猫狗标签  ##\n",
    "dogs_class = [ 'n02085620','n02085782','n02085936','n02086079','n02086240','n02086646','n02086910','n02087046','n02087394','n02088094',\n",
    "              'n02088238','n02088364','n02088466','n02088632','n02089078','n02089867','n02089973','n02090379','n02090622','n02090721',\n",
    "              'n02091032','n02091134','n02091244','n02091467','n02091635','n02091831','n02092002','n02092339','n02093256','n02093428',\n",
    "              'n02093647','n02093754','n02093859','n02093991','n02094114','n02094258','n02094433','n02095314','n02095570','n02095889',\n",
    "              'n02096051','n02096177','n02096294','n02096437','n02096585','n02097047','n02097130','n02097209','n02097298','n02097474',\n",
    "              'n02097658','n02098105','n02098286','n02098413','n02099267','n02099429','n02099601','n02099712','n02099849','n02100236',\n",
    "              'n02100583','n02100735','n02100877','n02101006','n02101388','n02101556','n02102040','n02102177','n02102318','n02102480',\n",
    "              'n02102973','n02104029','n02104365','n02105056','n02105162','n02105251','n02105412','n02105505','n02105641','n02105855',\n",
    "              'n02106030','n02106166','n02106382','n02106550','n02106662','n02107142','n02107312','n02107574','n02107683','n02107908',\n",
    "              'n02108000','n02108089','n02108422','n02108551','n02108915','n02109047','n02109525','n02109961','n02110063','n02110185',\n",
    "              'n02110341','n02110627','n02110806','n02110958','n02111129','n02111277','n02111500','n02111889','n02112018','n02112137',\n",
    "              'n02112350','n02112706','n02113023','n02113186','n02113624','n02113712','n02113799','n02113978']\n",
    "\n",
    "cats_class =['n02123045','n02123159','n02123394','n02123597','n02124075','n02125311','n02127052']\n",
    "\n",
    "model_ResNet50={'name':ResNet50,'shape':(224,224),'preprocess':None}\n",
    "model_VGG16={'name':VGG16,'shape':(224,224),'preprocess':None}\n",
    "model_VGG19={'name':VGG19,'shape':(224,224),'preprocess':None}\n",
    "model_InceptionV3={'name':InceptionV3,'shape':(299,299),'preprocess':inception_v3.preprocess_input}\n",
    "model_Xception={'name':Xception,'shape':(299,299),'preprocess':xception.preprocess_input}\n",
    "model_InceptionResNetV2={'name':InceptionResNetV2,'shape':(299,299),'preprocess':inception_resnet_v2.preprocess_input}\n",
    "\n",
    "def check_err_picture(model,model_shape,preprocess_input,picture_names,correct_class):    \n",
    "    bad_pict=[]\n",
    "    both_pict=[]\n",
    "    \n",
    "    for file in  tqdm(picture_names):\n",
    "        img = load_img(r'E:\\project-py\\dog_cat\\train\\\\'+file, target_size=model_shape)\n",
    "        x = img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        if preprocess_input:\n",
    "            x = preprocess_input(x)\n",
    "        \n",
    "        preds = model.predict(x)\n",
    "        pred_class=densenet.decode_predictions(preds, top=50)[0]\n",
    "        check_class=[(lambda x:x[0])(x) for x in pred_class]\n",
    "        \n",
    "        func_dog=(lambda x,y:len(set(x).intersection(set(y))))(pred_class,dogs_class)\n",
    "        func_cat=(lambda x,y:len(set(x).intersection(set(y))))(pred_class,cats_class)\n",
    "            \n",
    "        if pict_tpye=='DOG':\n",
    "            #  如果与标签类型无交集，说明预测top50不包含指定标签类型\n",
    "            if func_dog==0:\n",
    "                bad_pict.append(file)\n",
    "            #  如果同时包含有猫狗标签，可能会存在第二种异常类型\n",
    "            if (func_dog>0 and func_cat>0):\n",
    "                both_pict.append(file)\n",
    "        elif pict_tpye=='CAT':\n",
    "            if func_cat==0:\n",
    "                bad_pict.append(file)\n",
    "            if (func_dog>0 and func_cat>0):\n",
    "                both_pict.append(file)\n",
    "        \n",
    "    return bad_pict,both_pict\n",
    "        \n",
    "\n",
    "def check_error_pict(model_name):\n",
    "    err_list=[]\n",
    "    both_list=[]\n",
    "    \n",
    "    model = model_name['name'](weights='imagenet')\n",
    "    shape = model_name['shape']\n",
    "    preprocess_input=model_name['preprocess']\n",
    "    \n",
    "    dog_err,both1=check_err_picture(model,shape,preprocess_input,dogs,'DOG')\n",
    "    cat_err,both2=check_err_picture(model,shape,preprocess_input,cats,'CAT')\n",
    "    err_list=(dog_err+cat_err)\n",
    "    both_list=(both1+both2)\n",
    "    return err_list,both_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_ResNet50,both_ResNet50=check_error_pict(model_ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_VGG16,both_VGG16=check_error_pict(model_VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_VGG19,both_VGG19=check_error_pict(model_VGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_err=sorted(list(set(err_ResNet50).intersection(set(err_VGG16)).intersection(set(err_VGG19))))\n",
    "all_both=sorted(list(set(both_ResNet50).intersection(set(both_VGG16)).intersection(set(both_VGG19))))\n",
    "\n",
    "print(len(all_err))\n",
    "print(len(all_both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "all_err=['cat.10029.jpg', 'cat.10365.jpg', 'cat.10536.jpg', 'cat.10636.jpg', 'cat.10700.jpg', 'cat.10712.jpg', 'cat.11194.jpg', 'cat.11297.jpg', 'cat.11701.jpg', 'cat.12227.jpg', 'cat.12272.jpg', 'cat.12424.jpg', 'cat.12476.jpg', 'cat.166.jpg', 'cat.2337.jpg', 'cat.241.jpg', 'cat.2457.jpg', 'cat.252.jpg', 'cat.2520.jpg', 'cat.2663.jpg', 'cat.2758.jpg', 'cat.2817.jpg', 'cat.3410.jpg', 'cat.3738.jpg', 'cat.4308.jpg', 'cat.4338.jpg', 'cat.4688.jpg', 'cat.4842.jpg', 'cat.5351.jpg', 'cat.5418.jpg', 'cat.5780.jpg', 'cat.5880.jpg', 'cat.6345.jpg', 'cat.6442.jpg', 'cat.7377.jpg', 'cat.7564.jpg', 'cat.7661.jpg', 'cat.7671.jpg', 'cat.7968.jpg', 'cat.8456.jpg', 'cat.8470.jpg', 'cat.9090.jpg', 'cat.9110.jpg', 'cat.9171.jpg', 'cat.9983.jpg', 'dog.2422.jpg', 'dog.2614.jpg', 'dog.5604.jpg', 'dog.6733.jpg']\n",
    "\n",
    "plt.figure(figsize=(50,100),dpi=90)\n",
    "sorted_pict=sorted(all_err)\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(5):\n",
    "        if i*5+j < len(sorted_pict):\n",
    "            err_file=sorted_pict[i*5+j]\n",
    "            pict=cv2.resize(cv2.imread(r'E:\\project-py\\dog_cat\\train\\\\'+err_file),(300,300))            \n",
    "            plt.subplot(10,5, i*5+j+1)\n",
    "            plt.title(err_file)\n",
    "            plt.imshow(pict)\n",
    "            plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 移除异常值\n",
    "通过仔细识别图片，确定哪些图片属于异常值，然后从预训练数据集中移除异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline_err=[]\n",
    "outline_both=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outline(outline_set):\n",
    "    for x in outline_err:\n",
    "        if x[:3]=='dog':\n",
    "            dogs.remove(outline_err)\n",
    "        elif x[:3]=='cat':\n",
    "            cats.remove(outline_err)\n",
    "\n",
    "remove_outline(outline_err)\n",
    "remove_outline(outline_both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dogs_train,dogs_valid,dog_lable_train,dog_lable_valid=train_test_split(dogs,dog_lable,test_size=0.2,random_state=10,shuffle=True)\n",
    "cats_train,cats_valid,dog_lable_train,dog_lable_valid=train_test_split(cats,dog_lable,test_size=0.2,random_state=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('train2'):\n",
    "    shutil.rmtree('train2')\n",
    "    os.mkdir('train2')\n",
    "    os.mkdir(r'train2/cat')\n",
    "    os.mkdir(r'train2/dog')\n",
    "else:\n",
    "    os.mkdir('train2')\n",
    "    os.mkdir(r'train2/cat')\n",
    "    os.mkdir(r'train2/dog')\n",
    "\n",
    "if os.path.exists('valid'):\n",
    "    shutil.rmtree('valid')\n",
    "    os.mkdir('valid')\n",
    "    os.mkdir(r'valid/cat')\n",
    "    os.mkdir(r'valid/dog')\n",
    "else:\n",
    "    os.mkdir('valid')\n",
    "    os.mkdir(r'valid/cat')\n",
    "    os.mkdir(r'valid/dog')\n",
    "\n",
    "if os.path.exists('test2'):\n",
    "    shutil.rmtree('test2')\n",
    "else:\n",
    "    os.mkdir('test2')\n",
    "\n",
    "def link_image(image_name,train_valid,dog_or_cats):\n",
    "    for file in image_name:\n",
    "        if train_valid=='T':\n",
    "            if dog_or_cats =='CAT':\n",
    "                os.symlink(r'train/'+file,r'train2/cat/'+file)\n",
    "            else:\n",
    "                os.symlink(r'train/'+file,r'train2/dog/'+file)\n",
    "        else:\n",
    "            if dog_or_cats =='CAT':\n",
    "                os.symlink(r'train/'+file,r'valid/cat/'+file)\n",
    "            else:\n",
    "                os.symlink(r'train/'+file,r'valid/dog/'+file)\n",
    "\n",
    "link_image(dogs_train,'T','DOG')   \n",
    "link_image(dogs_valid,'V','DOG')    \n",
    "link_image(cats_train,'T','CAT')    \n",
    "link_image(cats_valid,'V','CAT')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for windows\n",
    "!tree\n",
    "#for linux\n",
    "#!tree -d\n",
    "\n",
    "print('\\n')\n",
    "print('statistics:')\n",
    "print('totol train pictures  :{}'.format(len(os.listdir('train'))))\n",
    "print('totol test  pictures  :{}'.format(len(os.listdir('test'))))\n",
    "print('train      set:  cats :{}'.format(len(os.listdir(r'train2/cat'))))\n",
    "print('train      set:  dogs :{}'.format(len(os.listdir(r'train2/dog'))))\n",
    "print('validation set:  cats :{}'.format(len(os.listdir(r'valid/cat'))))\n",
    "print('validation set:  dogs :{}'.format(len(os.listdir(r'valid/dog'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "dog_path=r'train/'+random.choice(dogs)\n",
    "cat_path=r'train/'+random.choice(cats)\n",
    "\n",
    "dog_pict=cv2.resize(cv2.imread(dog_path),(200,200))\n",
    "cat_pict=cv2.resize(cv2.imread(cat_path),(200,200))\n",
    "\n",
    "plt.figure(figsize=(10,5),dpi=90)\n",
    "p1=plt.subplot(1,2,1)\n",
    "p2=plt.subplot(1,2,2)\n",
    "p1.set_title(\"random dog\")\n",
    "p2.set_title(\"random cat\")\n",
    "p1.imshow(dog_pict)\n",
    "p2.imshow(cat_pict)\n",
    "p1.axis('off')\n",
    "p2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "'''\n",
    "input1 = Input(shape=(299, 299, 3))\n",
    "input2 = Input(shape=(224, 224, 3))\n",
    "input_set=[input1,input2]\n",
    "'''\n",
    "\n",
    "model_ResNet50={'name':ResNet50,'shape':(224,224),'preprocess':None}\n",
    "model_VGG16={'name':VGG16,'shape':(224,224),'preprocess':None}\n",
    "model_VGG19={'name':VGG19,'shape':(224,224),'preprocess':None}\n",
    "model_InceptionV3={'name':InceptionV3,'shape':(299,299),'preprocess':inception_v3.preprocess_input}\n",
    "model_Xception={'name':Xception,'shape':(299,299),'preprocess':xception.preprocess_input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_model(model_input,model_dict):\n",
    "    if model_dict['preprocess']:\n",
    "        x = Lambda(model_dict['preprocess'])(model_input)\n",
    "    else:\n",
    "        x=model_input\n",
    "        \n",
    "    base_model=model_dict['name'](input_tensor=x,weights='imagenet',include_top=False)\n",
    "    for layers in base_model.layers:\n",
    "        layers.trainable = False\n",
    "    return base_model\n",
    "\n",
    "def model_concatenate(input_set,model_set):\n",
    "    #input1 = Input(shape=(299, 299, 3))\n",
    "    input1=input_set[0]\n",
    "    #input2 = Input(shape=(224, 224, 3))\n",
    "    input2=input_set[1]\n",
    "\n",
    "    mid_out=[]\n",
    "    \n",
    "    for i in range(len(model_set)):\n",
    "        if model_set[i] in [model_Xception,model_InceptionV3]:\n",
    "            base_model=import_model(input1,model_set[i])\n",
    "        else:\n",
    "            base_model=import_model(input2,model_set[i])\n",
    "    \n",
    "        pool_layer=GlobalAveragePooling2D()(base_model.output)\n",
    "        mid_out.append(pool_layer)\n",
    "    \n",
    "    #print(mid_out)\n",
    "    \n",
    "    if (len(model_set)>1):\n",
    "        x= Concatenate(axis=-1)(mid_out)\n",
    "    else:\n",
    "        x=mid_out[0]\n",
    "    \n",
    "    x = Dropout(0.5)(x)\n",
    "    out=Dense(1,activation='sigmoid')(x)\n",
    "    #print(out)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def input_define(mask):\n",
    "    input_tensor=[]\n",
    "    if mask[0]==1:\n",
    "        input_tensor.append(Input(shape=(299, 299, 3)))\n",
    "    if mask[1]==1:\n",
    "        input_tensor.append(Input(shape=(224, 224, 3)))\n",
    "    return input_tensor\n",
    "\n",
    "\n",
    "def img_load_mask_transfer(input_type,mask,enhance=False):\n",
    "    masked_load=[]\n",
    "    \n",
    "    # enhance parameter for train\n",
    "    if enhance:\n",
    "        if input_type=='train':\n",
    "            data_gen_args = dict(featurewise_center=True,\n",
    "                         featurewise_std_normalization=True,\n",
    "                         rotation_range=90.,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         zoom_range=0.2)\n",
    "    else:\n",
    "        data_gen_args = dict()\n",
    "\n",
    "    #   directories  from different input        \n",
    "    if (input_type=='train'):\n",
    "        load_direct=r'train2'\n",
    "    elif (input_type=='valid'):\n",
    "        load_direct=r'valid'\n",
    "\n",
    "    #   mask  ImageDataGenerator   \n",
    "    if mask[0]==1:\n",
    "        image_size=(299,299)\n",
    "        gen1 = ImageDataGenerator(**data_gen_args)\n",
    "        image_gen1=gen1.flow_from_directory(directory=load_direct,class_mode='binary',target_size=(299, 299),batch_size=20,seed=1)\n",
    "        masked_load.append(image_gen1)\n",
    "    if mask[1]==1:\n",
    "        image_size=(224,224)\n",
    "        gen2 = ImageDataGenerator(**data_gen_args)\n",
    "        image_gen2 = gen2.flow_from_directory(directory=load_direct,class_mode='binary',target_size=(224,224),batch_size=20,seed=1)\n",
    "        masked_load.append(image_gen2)\n",
    "    # if not use append  then use zip\n",
    "    if sum(mask)>1:\n",
    "        return(zip(image_gen1,image_gen2))\n",
    "    else:\n",
    "        return masked_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建基础模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set=[model_ResNet50,model_Xception]\n",
    "\n",
    "##   model_mask   used for mask input(train,valid,test)\n",
    "model_mask=[0,0]\n",
    "for i in range(len(model_set)):\n",
    "    if model_set[i] in [model_Xception,model_InceptionV3]:\n",
    "        model_mask[0]=1\n",
    "    else:\n",
    "        model_mask[1]=1\n",
    "\n",
    "print(model_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_set=input_define(model_mask)\n",
    "print(input_set)\n",
    "\n",
    "out=model_concatenate(input_set,model_set)\n",
    "\n",
    "model = Model(input_set, out)\n",
    "\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load=img_load_mask_transfer('train',model_mask,True)\n",
    "print(train_load)\n",
    "#print(train_load[0].__dict__)\n",
    "\n",
    "valid_load=img_load_mask_transfer('valid',model_mask)\n",
    "#print(valid_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train, y_train, batch_size=128, nb_epoch=8, validation_split=0.2)\n",
    "\n",
    "hist = model.fit_generator(train_load, epochs=10, validation_data=valid_load ,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "history=np.load(npy_dir_path)  \n",
    "history=history.tolist()  \n",
    "acc=history['acc']  \n",
    "loss=history['loss']  \n",
    "val_acc=history['val_acc']  \n",
    "val_loss=history['val_loss']  \n",
    "nb_epoach=np.size(acc)  \n",
    "  \n",
    "plt.xlabel('Epochs')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.title('VGG-16 Loss Trend')  \n",
    "plt.plot(loss,'blue',label='Training Loss')  \n",
    "plt.plot(val_loss,'green',label='Validation Loss')  \n",
    "plt.xticks(range(0,nb_epoach))  \n",
    "plt.legend()  \n",
    "plt.show()  \n",
    "  \n",
    "plt.xlabel('Epochs')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.title('VGG-16 Accuracy Trend')  \n",
    "plt.plot(acc,'blue',label='Training Loss')  \n",
    "plt.plot(val_acc,'green',label='Validation Loss')  \n",
    "plt.xticks(range(0,nb_epoach))  \n",
    "plt.legend()  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print('Model name: {}'.format(model_set))\n",
    "    print('  seq        layer_name')\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_test= ImageDataGeneraotr().flow_from_directory(directory='test',class_mode=None,shuffle=False,\n",
    "                                                   target_size=target_size, batch_size=batch_size)\n",
    "predict=model.predict_generator(gen_test,)\n",
    "filenames = test_gen.filenames\n",
    "\n",
    "y_pred = model.predict_generator(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
